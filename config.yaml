# Configuration file for Russian-English Translation Model

# Model Architecture Configuration
model:
  src_vocab_size: 32000
  tgt_vocab_size: 32000
  d_model: 512              # Embedding dimension
  num_heads: 8              # Number of attention heads
  num_encoder_layers: 6     # Number of encoder layers
  num_decoder_layers: 6     # Number of decoder layers
  d_ff: 2048                # Feed-forward dimension
  max_len: 100              # Maximum sequence length
  dropout: 0.1              # Dropout rate

# Training Configuration
training:
  batch_size: 32
  epochs: 20
  warmup_steps: 4000
  label_smoothing: 0.1
  gradient_clip: 1.0
  learning_rate: 0.0001
  num_workers: 4
  
# Data Configuration
data:
  train_src: "data/processed/train.src"
  train_tgt: "data/processed/train.tgt"
  val_src: "data/processed/valid.src"
  val_tgt: "data/processed/valid.tgt"
  test_src: "data/processed/test.src"
  test_tgt: "data/processed/test.tgt"
  src_sp_model: "models/sp_en.model"
  tgt_sp_model: "models/sp_ru.model"
  
# Inference Configuration
inference:
  beam_size: 5
  length_penalty: 0.6
  max_len: 100